import streamlit as st
import re
import pandas as pd
from collections import defaultdict
from datetime import date 
import io 
from urllib.parse import quote 

# N√ÅZOV P√îVODN√âHO KARTAL√ìGVO√âHO S√öBORU
CATALOG_FILENAME = "ES Katalog biotopov Suvada ed 2023 v1.05.txt"

# --- CORE FACTORY AND DATA FUNCTIONS (Pre-cached) ---

def inner_dict_factory():
    """Pou≈æ√≠va sa ako factory pre vnoren√Ω defaultdict namiesto nesp√¥sobnej lambda funkcie."""
    return defaultdict(int)

@st.cache_data
def load_file_content(filename):
    """Naƒç√≠ta obsah katal√≥gu zo s√∫boru, sk√∫≈°a be≈æn√© k√≥dovania."""
    try:
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            with open(filename, 'r', encoding='Windows-1250') as f:
                return f.read()
    except FileNotFoundError:
        st.error(f"‚ö†Ô∏è CHYBA: S√∫bor s d√°tami '{filename}' sa nena≈°iel v prieƒçinku aplik√°cie.")
        st.caption("Uistite sa, ≈æe s√∫bor m√° presne tento n√°zov a je v rovnakom prieƒçinku ako python skript.")
        return None
    except Exception as e:
        st.error(f"Chyba pri naƒç√≠tan√≠ s√∫boru: {e}")
        return None

@st.cache_data
def parse_catalog_data(catalog_text):
    """Spracuje text katal√≥gu a extrahuje mapu synon√Ωm (Sekcia 1) a maticu podobnosti (Sekcia 4)."""
    
    lines = catalog_text.split('\n')
    section_1_active = False
    section_4_active = False
    
    synonym_map = {}
    similarity_matrix = defaultdict(inner_dict_factory)
    group_names = {}
    current_canonical_name = None
    
    # Regul√°rne v√Ωrazy 
    re_section_1_start = re.compile(r"SECTION 1:\s*Species aggregation", re.IGNORECASE)
    re_section_4_start = re.compile(r"SECTION 4:\s*Similarity", re.IGNORECASE) 
    re_section_end = re.compile(r"SECTION [23]:", re.IGNORECASE)
    re_canonical_name_1 = re.compile(r"^([A-Za-z].*?)\s+-\s*(\d+)\s*$")
    re_species_entry_1 = re.compile(r"^\s+([A-Za-z].*?)\s+(\d+)\s*$")
    re_group_name_4 = re.compile(r"^(Group\d+)\s*name:\s*(.+)\s*$") 
    re_species_name_only = re.compile(r"^\s*([A-Za-z].+?)\s*$", re.IGNORECASE) 
    re_total_line = re.compile(r"^\s*Total:\s*(\d+)\s*$", re.IGNORECASE)
    re_matrix_entry_4 = re.compile(r"^\s*(Group\d+):\s*(\d+)\s*$", re.IGNORECASE)
    
    current_species_in_matrix = None
    group_names_found = 0
    matrix_entries_found = 0

    for line in lines:
        line_clean = line.strip()

        if re_section_1_start.search(line):
            section_1_active = True; section_4_active = False; continue
        elif re_section_4_start.search(line):
            section_1_active = False; section_4_active = True; current_canonical_name = None; continue
        elif re_section_end.search(line):
            section_1_active = False; section_4_active = False; continue
        
        if section_1_active:
            match_canonical = re_canonical_name_1.match(line_clean)
            if match_canonical:
                current_canonical_name = match_canonical.group(1).strip()
                continue
            match_synonym = re_species_entry_1.match(line) 
            if match_synonym and current_canonical_name:
                synonym = match_synonym.group(1).strip()
                if synonym not in synonym_map: synonym_map[synonym] = current_canonical_name
            
        elif section_4_active:
            match_group_name = re_group_name_4.match(line_clean)
            if match_group_name:
                group_id = match_group_name.group(1).strip()
                # Uklad√°me pln√Ω n√°zov, ktor√Ω obsahuje aj k√≥d biotypu
                group_name_full = match_group_name.group(2).split(" Count:")[0].strip()
                group_names[group_id] = group_name_full
                group_names_found += 1
                continue
            
            if line_clean.startswith("Count:") or line_clean.startswith("No.") or line_clean.startswith("Frequency table"):
                continue

            match_species_line = re_species_name_only.match(line)
            if match_species_line and 'Total:' not in line and 'Group' not in line:
                current_species_in_matrix = match_species_line.group(1).strip()
                continue
            
            if re_total_line.match(line): continue
            
            match_matrix_entry = re_matrix_entry_4.match(line)
            if match_matrix_entry and current_species_in_matrix:
                group_id = match_matrix_entry.group(1).strip()
                try:
                    count = int(match_matrix_entry.group(2))
                    similarity_matrix[current_species_in_matrix][group_id] = count
                    matrix_entries_found += 1
                except ValueError: pass
                
    if not group_names_found or not matrix_entries_found:
        return None, None, None
         
    return synonym_map, group_names, similarity_matrix

@st.cache_data
def calculate_total_frequency_per_group(similarity_matrix, group_names):
    """Vypoƒç√≠ta s√∫ƒçet frekvenci√≠ pre V≈†ETKY kanonick√© druhy pre ka≈æd√Ω biotyp (Max Score)."""
    total_frequency = defaultdict(int)
    all_groups = set(group_names.keys())

    for canonical_name in similarity_matrix:
        species_data = similarity_matrix[canonical_name]
        for group_id, count in species_data.items():
            if group_id in all_groups:
                total_frequency[group_id] += count
    
    return dict(total_frequency)


def get_canonical_name(species_name, synonym_map):
    """Z√≠ska kanonick√© meno druhu, ak existuje, inak vr√°ti p√¥vodn√© meno."""
    species_name = species_name.strip()
    return synonym_map.get(species_name, species_name)

@st.cache_data
def get_all_known_species(synonym_map, similarity_matrix):
    """Z√≠ska zjednoten√Ω zoznam v≈°etk√Ωch zn√°mych druhov a synon√Ωm."""
    canonical_species = set(similarity_matrix.keys())
    all_known = canonical_species.union(set(synonym_map.keys())).union(set(synonym_map.values()))
    return sorted(list(all_known))

# NOV√Å FUNKCIA: Spracovanie nahran√©ho s√∫boru
def process_uploaded_species_list(uploaded_file, all_known_species):
    """
    Naƒç√≠ta druhy z TXT s√∫boru a rozdel√≠ ich na zn√°me a nezn√°me druhy.
    Predpoklad√°, ≈æe ka≈æd√Ω riadok je jeden druh.
    """
    
    known_species = []
    unknown_species = []
    
    # Sk√∫≈°ame r√¥zne k√≥dovania (utf-8, Windows-1250)
    try:
        string_data = uploaded_file.getvalue().decode("utf-8")
    except UnicodeDecodeError:
        try:
            string_data = uploaded_file.getvalue().decode("windows-1250")
        except:
            return None, None # Chyba k√≥dovania
            
    # Spracovanie riadkov
    for line in string_data.split('\n'):
        # Oƒçist√≠me riadok (trim, odstr√°nenie tabul√°torov/viacn√°sobn√Ωch medzier)
        species = re.sub(r'\s+', ' ', line).strip()
        
        if species:
            if species in all_known_species:
                known_species.append(species)
            else:
                unknown_species.append(species)
                
    # Odstr√°nenie duplik√°tov
    known_species = sorted(list(set(known_species)))
    unknown_species = sorted(list(set(unknown_species)))
    
    return known_species, unknown_species


# --- ANALYTICK√Å FUNKCIA S FQI V√ùPOƒåTOM ---

@st.cache_data(show_spinner="Prebieha v√Ωpoƒçet Frekvenƒçn√©ho Indexu (FQI)...")
def analyze_similarity(species_list, synonym_map, group_names, similarity_matrix, total_frequency_per_group):
    """
    Vyhodnot√≠ podobnos≈• k biotopom (skupin√°m).
    FQI = (Kumulat√≠vne sk√≥re zadan√Ωch druhov / Celkov√© mo≈æn√© sk√≥re skupiny) * 100
    Tie≈æ sleduje, ktor√© vstupy boli preskoƒçen√© (kanonick√Ω duplik√°t).
    """
    
    cumulative_scores = defaultdict(int)
    valid_groups = set(group_names.keys())
    # OPRAVA: Premenn√° iniciovan√° ako 'processed_species'
    processed_species = set() 
    name_conversion_map = {} 
    ignored_inputs = [] 
    
    # 1. KUMULAT√çVNE Sƒå√çTANIE A KONVERZIA
    for user_species in species_list:
        user_species = user_species.strip()
        canonical_name = get_canonical_name(user_species, synonym_map)
        
        if canonical_name in similarity_matrix:
            
            name_conversion_map[user_species] = canonical_name

            if canonical_name not in processed_species:
                processed_species.add(canonical_name)
                
                species_data = similarity_matrix[canonical_name]
                for group_id, count in species_data.items():
                    if group_id in valid_groups:
                        cumulative_scores[group_id] += count
            else:
                # Kanonick√Ω druh bol u≈æ spracovan√Ω, tento vstup ignorujeme
                ignored_inputs.append(user_species)
                

    if not cumulative_scores:
        # Pou≈æ√≠vame processed_species
        return None, processed_species, name_conversion_map, ignored_inputs 

    # 2. V√ùPOƒåET FQI (Percentu√°lna normaliz√°cia)
    fqi_scores = {}
    
    for group_id, cumulative_score in cumulative_scores.items():
        max_score = total_frequency_per_group.get(group_id, 0)
        
        if max_score > 0:
            fqi = (cumulative_score / max_score) * 100
            fqi_scores[group_id] = fqi
        else:
            fqi_scores[group_id] = 0.0

    # 3. ZORADENIE A V√ùBER TOP 3
    sorted_scores = sorted(fqi_scores.items(), key=lambda item: item[1], reverse=True)
    top_matches_data = []
    
    # Regex pre robustn√∫ extrakciu k√≥du (prv√Ω non-whitespace token) a zvy≈°ku n√°zvu
    re_biotope_code_extractor = re.compile(r'^(\S+)\s+(.*)', re.IGNORECASE)

    for rank, (group_id, score) in enumerate(sorted_scores[:3]):
        biotope_full_name = group_names.get(group_id, f"Nezn√°my Biotop ({group_id})")
        
        # P√¥vodn√Ω group_id (napr. Group42) ako fallback
        biotope_code = group_id 
        biotope_name = biotope_full_name

        match_code = re_biotope_code_extractor.match(biotope_full_name)
        
        if match_code:
            # Ak regex n√°jde zhodu
            biotope_code = match_code.group(1).strip() 
            biotope_name = match_code.group(2).strip()
            
            # Odstr√°nenie voliteƒænej pomlƒçky/medzier na zaƒçiatku n√°zvu, ak tam zostala
            if biotope_name.startswith('-'):
                 biotope_name = biotope_name[1:].strip()

        
        top_matches_data.append({
            'Poradie': rank + 1,
            'K√ìD Biotopu': biotope_code, # Zobrazi≈• skratku LES05.1a, TRB01a atƒè.
            'N√°zov Biotopu': biotope_name, # Zobrazi≈• pln√Ω n√°zov
            'FQI (% Zhody)': f"{score:.2f} %", 
        })

    return top_matches_data, processed_species, name_conversion_map, ignored_inputs

# --- EXPORTN√Å FUNKCIA PRE TXT ---

def generate_export_data(fqi_results_df, canonical_species_list, manual_data):
    """
    Generuje ucelen√Ω textov√Ω re≈•azec pre export obsahuj√∫ci hlaviƒçku, FQI v√Ωsledky a zoznam druhov.
    """
    
    # Doln√© indexy pre et√°≈æe
    E3, E2, E1, E0 = "\u2083", "\u2082", "\u2081", "\u2080"
    
    # Prevod DataFrame na textov√∫ tabuƒæku (CSV s tabul√°torom pre ƒçitateƒænos≈•)
    fqi_table = fqi_results_df.reset_index(drop=True).to_csv(sep='\t', index=False)
    
    output = "--- EXPORT V√ùSLEDKOV ANAL√ùZY BIOTOPU ---\n"
    output += "podƒæa publik√°cie ≈†uvada R. (ed.), 2023: Katal√≥g biotopov Slovenska. Druh√©, roz≈°√≠ren√© vydanie.\n\n"

    # 1. HLAVIƒåKA PRE MANU√ÅLNY Z√ÅPIS
    output += "SEKCIA 1: √öDAJE Z TER√âNU (VYPLNEN√â V APLIK√ÅCII)\n"
    output += "--------------------------------------------------\n"
    output += f"Lokalita:              {manual_data['lokalita']}\n"
    output += f"S√∫radnice:             {manual_data['suradnica']}\n"
    output += f"Meno mapovateƒæa:       {manual_data['mapovatel']}\n"
    output += f"D√°tum:                 {manual_data['datum'].strftime('%Y-%m-%d') if isinstance(manual_data['datum'], date) else manual_data['datum']}\n"
    output += f"Pokryvnos≈• et√°≈æ√≠ (E{E3}: stromov√©, E{E2}: krovit√©, E{E1}: bylinn√©, E{E0}: machov√©/li≈°ajn√≠kov√©):\n"
    output += f"  E{E3}:                  {manual_data['pokryvnost_E3']}\n"
    output += f"  E{E2}:                  {manual_data['pokryvnost_E2']}\n"
    output += f"  E{E1}:                  {manual_data['pokryvnost_E1']}\n"
    output += f"  E{E0}:                  {manual_data['pokryvnost_E0']}\n\n"
    
    # 2. V√ùSLEDKY FQI ANAL√ùZY
    output += "SEKCIA 2: V√ùSLEDKY FQI ANAL√ùZY (TOP 3)\n"
    output += "--------------------------------------------------\n"
    output += fqi_table
    output += "\n"

    # 3. KANONICK√â DRUHY
    output += "SEKCIA 3: POU≈ΩIT√â KANONICK√â DRUHY\n"
    output += "--------------------------------------------------\n"
    output += "Poƒçet kanonick√Ωch druhov: " + str(len(canonical_species_list)) + "\n"
    output += "\n".join(sorted(canonical_species_list))
    
    # NOV√â ZMENY PRE EXPORT NEZN√ÅMYCH DRUHOV
    remaining_unknown_species = manual_data.get('remaining_unknown_species')
    # Zabezpeƒç√≠me, ≈æe zoznam je k dispoz√≠cii
    manual_selections_for_analysis = manual_data.get('manual_selections_for_analysis', []) 
    
    if manual_selections_for_analysis:
        # Sekcia 4: MANU√ÅLNE PRIDAN√â DRUHY
        output += "\n\nSEKCIA 4: MANU√ÅLNE PRIDAN√â DRUHY (Korekcia/Doplnenie)\n"
        output += "--------------------------------------------------\n"
        output += "Druhy, ktor√© boli manu√°lne pridan√©/korigovan√© v kroku 1.2:\n"
        output += "\n".join(manual_selections_for_analysis)

    if remaining_unknown_species:
        # Sekcia 5: NEZARADEN√â DRUHY (s upraven√Ωm textom)
        output += "\n\nSEKCIA 5: NEZARADEN√â DRUHY\n"
        output += "--------------------------------------------------\n"
        output += "Men√° druhov z importovan√©ho s√∫boru, ktor√© nebolo mo≈æn√© automaticky priradi≈• ku kanonick√Ωm druhom:\n" 
        output += "\n".join(remaining_unknown_species)
    # KONIEC NOV√ùCH ZMIEN
    
    output += "\n\n--- KONIEC EXPORTU ---\n"
    
    return output

# --- EXPORTN√Å FUNKCIA PRE XLSX ---

def generate_excel_data(fqi_results_df, canonical_species_list, manual_data):
    """Generuje Excel s√∫bor (.xlsx) s tromi listami d√°t."""
    
    # Doln√© indexy pre et√°≈æe
    E3, E2, E1, E0 = "\u2083", "\u2082", "\u2081", "\u2080"
    
    # 1. PRIPRAVA DAT PRE HLAVICKU (ako DataFrame)
    header_data = [
        ("--- Z√ÅKLADN√â √öDAJE ---", ""),
        ("Lokalita", manual_data['lokalita']),
        ("S√∫radnice", manual_data['suradnica']),
        ("Meno mapovateƒæa", manual_data['mapovatel']),
        ("D√°tum", manual_data['datum'].strftime('%Y-%m-%d') if isinstance(manual_data['datum'], date) else manual_data['datum']),
        ("--- POKRYVNOS≈§ ET√Å≈Ω√ç ---", ""),
        (f"E{E3} (Stromov√© poschodie)", manual_data['pokryvnost_E3']),
        (f"E{E2} (Krovit√© poschodie)", manual_data['pokryvnost_E2']),
        (f"E{E1} (Bylinn√© poschodie)", manual_data['pokryvnost_E1']),
        (f"E{E0} (Machov√©/Li≈°. poschodie)", manual_data['pokryvnost_E0']),
    ]
    df_header = pd.DataFrame(header_data, columns=['Popis', 'Hodnota'])
    
    # 2. PRIPRAVA DAT PRE DRUHY
    df_species = pd.DataFrame(sorted(canonical_species_list), columns=['Kanonick√© druhy (pou≈æit√© v anal√Ωze)'])
    
    # NOV√â ZMENY: D√°ta o stave nezn√°mych druhov
    remaining = manual_data.get('remaining_unknown_species', [])
    manual_added = manual_data.get('manual_selections_for_analysis', [])
    
    df_status = pd.DataFrame({
        'Stav': 
            ['Manu√°lne pridan√© (zaraden√© do anal√Ωzy)'] * len(manual_added) + 
            ['Nezaraden√© (p√¥vodn√Ω nezn√°my/preklep)'] * len(remaining),
        'Druh': manual_added + remaining
    })
    
    # 3. ZAPIS DO BYTESIO BUFFERU
    output = io.BytesIO()
    
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        
        # A. Manu√°lne √∫daje (Hlaviƒçka)
        df_header.to_excel(writer, sheet_name='Data z ter√©nu', index=False, startrow=0, startcol=0)

        # B. FQI V√Ωsledky (u≈æ je DataFrame)
        df_fqi_excel = fqi_results_df.copy()
        df_fqi_excel.to_excel(writer, sheet_name='FQI V√Ωsledky', index=False, startrow=0, startcol=0)

        # C. Kanonick√© druhy
        df_species.to_excel(writer, sheet_name='Kanonick√© druhy', index=False, startrow=0, startcol=0)

        # D. NOV√â: Stav nezn√°mych druhov
        if not df_status.empty:
            df_status.to_excel(writer, sheet_name='Stav Nezn√°mych Druhov', index=False, startrow=0, startcol=0)

        # Optimaliz√°cia ≈°√≠rky stƒ∫pcov pre lep≈°iu ƒçitateƒænos≈•
        for sheetname in writer.sheets:
            worksheet = writer.sheets[sheetname]
            # Nastav√≠ ≈°√≠rku pre prv√© 4 stƒ∫pce
            worksheet.set_column('A:D', 30)
            
    # Resetovanie poz√≠cie bufferu a vr√°tenie obsahu
    output.seek(0)
    return output.read()

# --- AKCIE PRE TLAƒåIDL√Å (Callbacks) ---

def calculate_fqi_action():
    """Ulo≈æ√≠ aktu√°lny v√Ωber a prepne re≈æim na zobrazenie v√Ωsledkov."""
    
    # Spojenie ruƒçne vybran√Ωch a zn√°mych nahran√Ωch druhov
    uploaded_known = st.session_state.get('uploaded_known_species', [])
    manual_selected = st.session_state.selected_species_multiselect
    
    # Odstr√°nenie duplik√°tov medzi nahrat√Ωmi a ruƒçne vybran√Ωmi
    combined_species = list(set(uploaded_known + manual_selected))
    
    st.session_state['calculated_species'] = combined_species
    # NOVINKA: Explicitn√© ulo≈æenie manu√°lne vybran√Ωch druhov pre perzistentn√© zobrazenie v re≈æime "results"
    st.session_state['manual_selections_for_display'] = manual_selected 
    st.session_state['app_mode'] = 'results'
    
# Callback pre spracovanie nahran√©ho s√∫boru
def handle_upload():
    """Spracuje nahran√Ω s√∫bor a aktualizuje session state."""
    
    uploaded_file = st.session_state.uploaded_file_key
    all_known_species = st.session_state.all_known_species_data
    
    if uploaded_file is not None:
        known_species, unknown_species = process_uploaded_species_list(uploaded_file, all_known_species)
        
        if known_species is None:
             st.error("Chyba: Nepodarilo sa preƒç√≠ta≈• s√∫bor. Sk√∫ste in√© k√≥dovanie (napr. UTF-8 alebo Windows-1250).")
             return
             
        st.session_state['uploaded_known_species'] = known_species
        st.session_state['uploaded_unknown_species'] = unknown_species
        # Nech√°vame existuj√∫ci v√Ωber v multiselecte tak, ako je, ale upozorn√≠me na nov√∫ situ√°ciu
        st.toast(f"Naƒç√≠tan√Ωch druhov: {len(known_species) + len(unknown_species)}. Zn√°mych: {len(known_species)}, Nezn√°mych: {len(unknown_species)}.", icon='üìÑ')
    else:
        # Ak sa s√∫bor odstr√°ni
        st.session_state['uploaded_known_species'] = []
        st.session_state['uploaded_unknown_species'] = []
        st.toast("Nahrat√Ω s√∫bor bol odstr√°nen√Ω. Zoznam druhov z neho bol vyƒçisten√Ω.", icon='üóëÔ∏è')


def reset_selection_action():
    """Prepne re≈æim sp√§≈• na v√Ωber a vyƒçist√≠ stav nahran√©ho s√∫boru."""
    st.session_state['app_mode'] = 'selection'
    # Vyƒçistenie stavu pre hromadn√Ω upload a ruƒçn√Ω v√Ωber
    st.session_state['uploaded_known_species'] = []
    st.session_state['uploaded_unknown_species'] = []
    st.session_state['selected_species_multiselect'] = []
    # Vyƒçist√≠me aj perzistentn√Ω kƒæ√∫ƒç
    st.session_state['manual_selections_for_display'] = []


# --- HLAVN√Å WEB APLIK√ÅCIA ---

def biotope_web_app():
    
    st.set_page_config(page_title="Identifik√°tor Biotopov (FQI)", layout="wide")
    
    st.title("üåø Identifik√°tor Biotopov (FQI) na z√°klade Expertn√©ho Syst√©mu")
    st.caption(f"D√°ta naƒç√≠tan√© zo s√∫boru: **{CATALOG_FILENAME}**")

    # Cit√°cia
    st.markdown("""
        **Podƒæa publik√°cie:**
        ≈†uvada R. (ed.), 2023: Katal√≥g biotopov Slovenska. Druh√©, roz≈°√≠ren√© vydanie. ‚Äì
        ≈†t√°tna ochrana pr√≠rody SR, Bansk√° Bystrica, 511 p. ISBN 978-80-8184-106-4
    """)
    st.markdown("---")


    # Inicializ√°cia stavu
    if 'app_mode' not in st.session_state:
        st.session_state['app_mode'] = 'selection'
        st.session_state['calculated_species'] = [] 
        # PREMENN√â PRE HROMADN√ù UPLOAD
        st.session_state['uploaded_known_species'] = []
        st.session_state['uploaded_unknown_species'] = []
        st.session_state['selected_species_multiselect'] = [] # Stav pre multiselect - inicializovan√©
        st.session_state['manual_selections_for_display'] = [] # NOVINKA: Perzistentn√Ω stav manu√°lneho v√Ωberu

    # Krok 0: Naƒç√≠tanie a parsovanie d√°t (Cache d√°ta)
    catalog_text = load_file_content(CATALOG_FILENAME)
    if catalog_text is None:
        return

    synonym_map, group_names, similarity_matrix = parse_catalog_data(catalog_text)
    if synonym_map is None: 
        st.error("Nepodarilo sa spracova≈• d√°ta z katal√≥gu. Skontrolujte jeho form√°tovanie.")
        return
        
    all_species = get_all_known_species(synonym_map, similarity_matrix)
    total_frequency_per_group = calculate_total_frequency_per_group(similarity_matrix, group_names)

    # Ulo≈æenie ALL_SPECIES do session (potrebn√© pre handle_upload)
    st.session_state.all_known_species_data = all_species 

    # Sidebar ≈°tatistiky
    st.sidebar.header("≈†tatistiky D√°t")
    st.sidebar.write(f"Biotopov (skup√≠n): **{len(group_names)}**")
    st.sidebar.write(f"Spracovan√Ωch druhov v matici: **{len(similarity_matrix)}**")
    st.sidebar.write(f"Celkov√Ω poƒçet n√°zvov/synon√Ωm na v√Ωber: **{len(all_species)}**")


    # --- RIADENIE RE≈ΩIMU APLIK√ÅCIE ---

    if st.session_state['app_mode'] == 'selection':
        # Re≈æim 1: V√ùBER DRUHOV

        st.header("1. Zadanie Druhov")
        
        # NOV√Å FUNKCIONALITA: HROMADN√ù UPLOAD
        st.subheader("1.1. Hromadn√© zadanie (TXT s√∫bor)")
        # *** ZMENEN√ù TEXT PODƒΩA PO≈ΩIADAVKY ***
        st.info("Nahrajte textov√Ω s√∫bor, ktor√Ω bude ma≈• na riadku len meno jedn√©ho druhu bez inform√°cie o pokryvnosti. Aplik√°cia automaticky spracuje zn√°me druhy a identifikuje nezn√°me.")
        # ***********************************
        
        uploaded_file = st.file_uploader(
            "Vyberte TXT s√∫bor so zoznamom druhov", 
            type=['txt'], 
            on_change=handle_upload,
            key='uploaded_file_key'
        )

        uploaded_known_species = st.session_state.get('uploaded_known_species', [])
        uploaded_unknown_species = st.session_state.get('uploaded_unknown_species', [])

        if uploaded_file and (uploaded_known_species or uploaded_unknown_species):
            st.success(f"Naƒç√≠tan√Ωch zn√°mych druhov zo s√∫boru: **{len(uploaded_known_species)}**")
            
            # Zobrazenie nezn√°mych druhov
            if uploaded_unknown_species:
                st.warning(f"Nezn√°me druhy v s√∫bore (na manu√°lnu korekciu): **{len(uploaded_unknown_species)}**")
                st.caption("Tieto druhy nebud√∫ zahrnut√© do anal√Ωzy, k√Ωm ich neprirad√≠te k zn√°memu druhu pomocou ruƒçn√©ho v√Ωberu (mo≈ænos≈• 1.2).")
                # Zmena: Automatick√© rozbalenie zoznamu
                with st.expander("Zobrazi≈• nezn√°me druhy", expanded=True): 
                    st.code("\n".join(uploaded_unknown_species))
            
            st.markdown("---")


        # NOV√Å/UPRAVEN√Å FUNKCIONALITA: Ruƒçn√Ω v√Ωber alebo √∫prava
        st.subheader("1.2. Manu√°lny v√Ωber (doplnenie / √∫prava / korekcia)")

        # OPRAVA: Odstr√°nenie explicitn√©ho "default" na elimin√°ciu Streamlit varovania
        current_species_list = st.multiselect(
            "Vyberte druh zo zoznamu (zaƒçnite p√≠sa≈• pre filtrovanie), alebo n√≠m **korigujte nezn√°me druhy** zo s√∫boru:",
            options=all_species,
            key="selected_species_multiselect" 
        )
        
        # S√öHRN PRE ANAL√ùZU
        total_species_for_analysis = list(set(uploaded_known_species + current_species_list))

        st.info(f"Celkov√Ω poƒçet druhov pre FQI anal√Ωzu (zn√°me zo s√∫boru + ruƒçne vybran√©): **{len(total_species_for_analysis)}**")
        
        if total_species_for_analysis:
            st.button(
                "üü¢ V≈°etky druhy zadan√©, vypoƒç√≠taj FQI", 
                on_click=calculate_fqi_action, 
                use_container_width=True
            )
        else:
            st.button("V≈°etky druhy zadan√©, vypoƒç√≠taj FQI", disabled=True, use_container_width=True)


    elif st.session_state['app_mode'] == 'results':
        # Re≈æim 2: ZOBRAZENIE V√ùSLEDKOV

        user_species_list = st.session_state['calculated_species']
        uploaded_unknown_species = st.session_state.get('uploaded_unknown_species', [])
        # POU≈Ω√çVAME NOV√ö, PERZISTENTN√ö HODNOTU (manu√°lne vybran√© druhy v kroku 1.2)
        manual_selected_for_display = st.session_state.get('manual_selections_for_display', []) 
        uploaded_known_species = st.session_state.get('uploaded_known_species', []) 
        
        # ----------------------------------------------------
        # Zjednodu≈°en√° LOGIKA PRE KONTROLU DRUHOV
        # ----------------------------------------------------
        
        # Druhy, ktor√© boli P√îVODNE nezn√°me zo s√∫boru (tieto s√∫ nezaraden√©)
        remaining_unknown_species = uploaded_unknown_species 
        
        # Druhy, ktor√© boli MANU√ÅLNE pridan√©/korigovan√© v kroku 1.2. Tieto boli ZARADEN√â.
        manual_selections_for_analysis = manual_selected_for_display

        # KONTROLA PRE PODMIENEN√â ZOBRAZENIE
        # Zobraz√≠me detaily, len ak bol vykonan√Ω HROMADN√ù IMPORT
        show_processing_details = (
            len(uploaded_known_species) > 0 or
            len(uploaded_unknown_species) > 0 or
            len(manual_selections_for_analysis) > 0 # Zobrazi≈• aj ak bol iba manu√°lny v√Ωber
        )
        
        # ----------------------------------------------------

        if not user_species_list:
            st.error("Chyba: Neboli n√°jden√© ≈æiadne druhy na anal√Ωzu. Prepnite sp√§≈• na v√Ωber.")
            st.button("‚¨ÖÔ∏è Zme≈à druhov√∫ skupinu", on_click=reset_selection_action)
            return

        st.header("2. V√Ωsledky Anal√Ωzy FQI")
        
        st.button("‚¨ÖÔ∏è Zme≈à druhov√∫ skupinu", on_click=reset_selection_action)
        
        st.markdown("---")
        
        st.info(f"Anal√Ωza be≈æ√≠ pre **{len(user_species_list)}** vybran√Ωch druhov.")

        # Spustenie FQI anal√Ωzy (cache)
        top_matches_data, processed_species, name_conversion_map, ignored_inputs = analyze_similarity(
            user_species_list, synonym_map, group_names, similarity_matrix, total_frequency_per_group
        )
        
        if top_matches_data is None:
            st.error("Nena≈°iel sa ≈æiaden zadan√Ω druh v matici podobnosti. V√Ωpoƒçet FQI nie je mo≈æn√Ω.")
            processed_species = set()
            name_conversion_map = {}
            ignored_inputs = [] 
            return

        # Krok 3: Zobrazenie v√Ωsledkov
        
        # 3.1. TOP 3 ZHODY
        st.subheader("Biotopy s najvy≈°≈°ou podobnos≈•ou (FQI)")
        
        df_results = pd.DataFrame(top_matches_data)
        df_results_display = df_results.set_index('Poradie')
        st.dataframe(df_results_display, use_container_width=True)

        st.caption("FQI (Frekvenƒçn√Ω Index) je **%**, ktor√© vyjadruje podiel s√∫ƒçtu frekvenci√≠ vybran√Ωch druhov na celkovej mo≈ænej frekvencii v≈°etk√Ωch kanonick√Ωch druhov v danej skupine. Vy≈°≈°ie percento = Vy≈°≈°ia zhoda.")

        st.markdown("---")
        
        # --- SEKCIA 3: DETAIY SPRACOVANIA ---
        st.subheader("3. Detaily Spracovania")

        col1, col2, col3 = st.columns(3) 
        
        # PODMIENEN√â ZOBRAZENIE
        if show_processing_details:
            with st.expander("Kontrola spracovania druhov zo s√∫boru a manu√°lnych korekci√≠", expanded=True):
                
                # 1. ƒåo zostalo nezaraden√© (P√¥vodn√© nezn√°me) - TERAZ AKO PRV√â
                if remaining_unknown_species:
                    # Pou≈æitie upraven√©ho textu
                    st.warning(
                        f"**{len(remaining_unknown_species)}** druhov nebolo v anal√Ωze zahrnut√Ωch. Men√° druhov z importovan√©ho s√∫boru, ktor√© nebolo mo≈æn√© automaticky priradi≈• ku kanonick√Ωm druhom."
                    )
                    st.code("\n".join(remaining_unknown_species))
                    
                
                elif len(uploaded_unknown_species) > 0 and not remaining_unknown_species:
                    st.success("V≈°etky p√¥vodne nezn√°me druhy boli manu√°lne opraven√©/priraden√©.")
                elif len(uploaded_unknown_species) == 0 and len(uploaded_known_species) > 0:
                    st.success("V nahratom s√∫bore neboli ≈æiadne nezn√°me druhy.")
                    
                
                # 2. ƒåo bolo manu√°lne pridan√© (Potenci√°lne opraven√©) - TERAZ AKO DRUH√â
                if manual_selections_for_analysis:
                    # Drobn√© oddelenie, len ak predch√°dzaj√∫ci blok nebol st.success/st.info
                    if remaining_unknown_species or len(uploaded_unknown_species) > 0:
                        st.markdown("") # Mal√Ω vertik√°lny priestor
                        
                    st.success(f"**{len(manual_selections_for_analysis)}** druhov bolo **manu√°lne pridan√Ωch/korigovan√Ωch** v kroku 1.2 a boli zahrnut√© do anal√Ωzy:")
                    st.code("\n".join(manual_selections_for_analysis))
                else:
                    # Zmenen√© z info na text, aby to vizu√°lne neza≈•a≈æovalo
                    if not remaining_unknown_species and not uploaded_known_species:
                        st.info("Do anal√Ωzy neboli pridan√© ≈æiadne druhy ruƒçn√Ωm v√Ωberom.")
                

        # P√¥vodn√© detaily spracovania
        with col1:
            st.markdown("##### Spracovan√© druhy (kanonick√©)")
            st.write(f"**Poƒçet spracovan√Ωch kanonick√Ωch druhov:** {len(processed_species)}")
            
            with st.expander("Zobrazi≈• pou≈æit√© kanonick√© men√°"):
                st.code("\n".join(sorted(list(processed_species))))

        with col2:
            conversions = {original: canonical for original, canonical in name_conversion_map.items() if original != canonical}
            
            st.markdown(f"##### Konverzie Synonym (zadan√Ω ‚Üí kanonick√Ω)")
            
            if conversions:
                df_conversions = pd.DataFrame(list(conversions.items()), columns=['Zadan√© meno', 'Kanonick√© meno'])
                st.dataframe(df_conversions, use_container_width=True, hide_index=True)
            else:
                st.success("Neboli zadan√© ≈æiadne synonym√°, alebo bol zadan√Ω u≈æ kanonick√Ω n√°zov.")

        with col3:
            st.markdown(f"##### Ignorovan√© duplik√°ty vstupu")
            
            if ignored_inputs:
                st.warning(f"**Ignorovan√Ωch vstupov: {len(ignored_inputs)}**")
                st.caption("Tieto druhy maj√∫ kanonick√© meno, ktor√© u≈æ bolo v r√°mci v√Ωpoƒçtu zahrnut√©. Boli preskoƒçen√©, aby sa predi≈°lo duplicitn√©mu zapoƒç√≠taniu.")
                with st.expander("Zobrazi≈• ignorovan√© vstupy"):
                    st.code("\n".join(ignored_inputs))
            else:
                st.success("Neboli zadan√© ≈æiadne duplik√°ty.")

        st.markdown("---") 

        # --- SEKCIA 4: √öDAJE Z TER√âNU A EXPORT ---
        st.subheader("4. √ödaje z ter√©nu a Export")
        
        # Pou≈æitie doln√Ωch indexov
        E3, E2, E1, E0 = "\u2083", "\u2082", "\u2081", "\u2080"
        
        # Uchovanie d√°t zadan√Ωch do formul√°ru pre export
        lokalita_default = st.session_state.get('export_lokalita', '')
        suradnica_default = st.session_state.get('export_suradnica', '')
        mapovatel_default = st.session_state.get('export_mapovatel', '')
        datum_default = st.session_state.get('export_datum', date.today())
        pokryvnost_E3_default = st.session_state.get('export_E3', '0')
        pokryvnost_E2_default = st.session_state.get('export_E2', '0')
        pokryvnost_E1_default = st.session_state.get('export_E1', '0')
        pokryvnost_E0_default = st.session_state.get('export_E0', '0')

        lokalita, suradnica, mapovatel, datum = lokalita_default, suradnica_default, mapovatel_default, datum_default
        pokryvnost_E3, pokryvnost_E2, pokryvnost_E1, pokryvnost_E0 = pokryvnost_E3_default, pokryvnost_E2_default, pokryvnost_E1_default, pokryvnost_E0_default

        with st.form("field_data_form"):
            
            col_a, col_b = st.columns([3, 1]) 
            
            with col_a:
                st.markdown("##### Inform√°cie o ter√©nnom z√°zname")
                
                lokalita = st.text_input("Lokalita", value=lokalita_default, key='export_lokalita')
                suradnica = st.text_input("S√∫radnice", value=suradnica_default, key='export_suradnica')
                mapovatel = st.text_input("Meno mapovateƒæa", value=mapovatel_default, key='export_mapovatel')
                datum = st.date_input("D√°tum z√°pisu", value=datum_default, key='export_datum')

            with col_b:
                st.markdown(f"##### Pokryvnos≈• et√°≈æ√≠ (E{E3}-E{E0})")
                
                help_text_etaze = "Pokryvnos≈• v %"
                pokryvnost_E3 = st.text_input(f"E{E3} (Stromov√© poschodie)", value=pokryvnost_E3_default, key='export_E3', help=help_text_etaze)
                pokryvnost_E2 = st.text_input(f"E{E2} (Krovit√© poschodie)", value=pokryvnost_E2_default, key='export_E2', help=help_text_etaze)
                pokryvnost_E1 = st.text_input(f"E{E1} (Bylinn√© poschodie)", value=pokryvnost_E1_default, key='export_E1', help=help_text_etaze)
                pokryvnost_E0 = st.text_input(f"E{E0} (Machov√©/Li≈°. poschodie)", value=pokryvnost_E0_default, key='export_E0', help=help_text_etaze)
                
            st.form_submit_button("Ulo≈æi≈• √∫daje (pred exportom)", type="primary")

        # Zostavenie manu√°lnych d√°t pre export
        manual_data = {
            'lokalita': lokalita,
            'suradnica': suradnica,
            'mapovatel': mapovatel,
            'datum': datum,
            'pokryvnost_E3': pokryvnost_E3,
            'pokryvnost_E2': pokryvnost_E2,
            'pokryvnost_E1': pokryvnost_E1,
            'pokryvnost_E0': pokryvnost_E0,
            # PRIDAN√â PRE EXPORT - pou≈æ√≠va perzistentn√∫ hodnotu pre konzistentnos≈•
            'manual_selections_for_analysis': manual_selections_for_analysis,
            'remaining_unknown_species': remaining_unknown_species,
        }

        # Generovanie obsahu pre TXT export
        export_data_str = generate_export_data(
            df_results, 
            list(processed_species), 
            manual_data
        )
        
        # Generovanie obsahu pre XLSX export
        excel_data_bytes = generate_excel_data(
            df_results, 
            list(processed_species), 
            manual_data
        )
        
        # Tlaƒçidl√° pre stiahnutie v stƒ∫pcoch (vyrovnan√© na jednom riadku)
        file_name_prefix = lokalita[:10].replace(' ', '_').strip() if lokalita else "novy_zapis"
        
        col_xlsx, col_txt = st.columns(2)
        
        with col_xlsx: 
            st.download_button(
                label="‚¨áÔ∏è Export v√Ωsledkov (Excel XLSX)",
                data=excel_data_bytes,
                file_name=f"biotop_analyza_{date.today().strftime('%Y%m%d')}_{file_name_prefix}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )

        with col_txt: 
            st.download_button(
                label="‚¨áÔ∏è Export v√Ωsledkov (TXT form√°t)",
                data=export_data_str,
                file_name=f"biotop_analyza_{date.today().strftime('%Y%m%d')}_{file_name_prefix}.txt",
                mime="text/plain",
                use_container_width=True
            )
            
        st.markdown("---") 
            

    # Copyright Footer
    st.markdown("<footer><p style='text-align: right; color: gray; font-size: small;'>¬© R√≥bert ≈†uvada 2025</p></footer>", unsafe_allow_html=True)


if __name__ == "__main__":
    biotope_web_app()