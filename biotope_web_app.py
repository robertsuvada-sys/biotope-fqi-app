import streamlit as st
import re
import pandas as pd
from collections import defaultdict

# N√ÅZOV V√Å≈†HO P√îVODN√âHO KARTAL√ìGVO√âHO S√öBORU
CATALOG_FILENAME = "ES Katalog biotopov Suvada ed 2023 v1.05.txt"

# --- CORE FACTORY AND DATA FUNCTIONS (Pre-cached) ---

def inner_dict_factory():
    """Pou≈æ√≠va sa ako factory pre vnoren√Ω defaultdict namiesto nesp√¥sobnej lambda funkcie."""
    return defaultdict(int)

@st.cache_data
def load_file_content(filename):
    """Naƒç√≠ta obsah katal√≥gu zo s√∫boru, sk√∫≈°a be≈æn√© k√≥dovania."""
    try:
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            with open(filename, 'r', encoding='Windows-1250') as f:
                return f.read()
    except FileNotFoundError:
        st.error(f"‚ö†Ô∏è CHYBA: S√∫bor s d√°tami '{filename}' sa nena≈°iel v prieƒçinku aplik√°cie.")
        st.caption("Uistite sa, ≈æe s√∫bor m√° presne tento n√°zov a je v rovnakom prieƒçinku ako python skript.")
        return None
    except Exception as e:
        st.error(f"Chyba pri naƒç√≠tan√≠ s√∫boru: {e}")
        return None

@st.cache_data
def parse_catalog_data(catalog_text):
    """Spracuje text katal√≥gu a extrahuje mapu synon√Ωm (Sekcia 1) a maticu podobnosti (Sekcia 4)."""
    
    lines = catalog_text.split('\n')
    section_1_active = False
    section_4_active = False
    
    synonym_map = {}
    similarity_matrix = defaultdict(inner_dict_factory)
    group_names = {}
    current_canonical_name = None
    
    # Regul√°rne v√Ωrazy 
    re_section_1_start = re.compile(r"SECTION 1:\s*Species aggregation", re.IGNORECASE)
    re_section_4_start = re.compile(r"SECTION 4:\s*Similarity", re.IGNORECASE) 
    re_section_end = re.compile(r"SECTION [23]:", re.IGNORECASE)
    re_canonical_name_1 = re.compile(r"^([A-Za-z].*?)\s+-\s*(\d+)\s*$")
    re_species_entry_1 = re.compile(r"^\s+([A-Za-z].*?)\s+(\d+)\s*$")
    re_group_name_4 = re.compile(r"^(Group\d+)\s*name:\s*(.+)\s*$") 
    re_species_name_only = re.compile(r"^\s*([A-Za-z].+?)\s*$", re.IGNORECASE) 
    re_total_line = re.compile(r"^\s*Total:\s*(\d+)\s*$", re.IGNORECASE)
    re_matrix_entry_4 = re.compile(r"^\s*(Group\d+):\s*(\d+)\s*$", re.IGNORECASE)
    
    current_species_in_matrix = None
    group_names_found = 0
    matrix_entries_found = 0

    for line in lines:
        line_clean = line.strip()

        if re_section_1_start.search(line):
            section_1_active = True; section_4_active = False; continue
        elif re_section_4_start.search(line):
            section_1_active = False; section_4_active = True; current_canonical_name = None; continue
        elif re_section_end.search(line):
            section_1_active = False; section_4_active = False; continue
        
        if section_1_active:
            match_canonical = re_canonical_name_1.match(line_clean)
            if match_canonical:
                current_canonical_name = match_canonical.group(1).strip()
                continue
            match_synonym = re_species_entry_1.match(line) 
            if match_synonym and current_canonical_name:
                synonym = match_synonym.group(1).strip()
                if synonym not in synonym_map: synonym_map[synonym] = current_canonical_name
            
        elif section_4_active:
            match_group_name = re_group_name_4.match(line_clean)
            if match_group_name:
                group_id = match_group_name.group(1).strip()
                # Uklad√°me pln√Ω n√°zov, ktor√Ω obsahuje aj k√≥d biotypu
                group_name_full = match_group_name.group(2).split(" Count:")[0].strip()
                group_names[group_id] = group_name_full
                group_names_found += 1
                continue
            
            if line_clean.startswith("Count:") or line_clean.startswith("No.") or line_clean.startswith("Frequency table"):
                continue

            match_species_line = re_species_name_only.match(line)
            if match_species_line and 'Total:' not in line and 'Group' not in line:
                current_species_in_matrix = match_species_line.group(1).strip()
                continue
            
            if re_total_line.match(line): continue
            
            match_matrix_entry = re_matrix_entry_4.match(line)
            if match_matrix_entry and current_species_in_matrix:
                group_id = match_matrix_entry.group(1).strip()
                try:
                    count = int(match_matrix_entry.group(2))
                    similarity_matrix[current_species_in_matrix][group_id] = count
                    matrix_entries_found += 1
                except ValueError: pass
                
    if not group_names_found or not matrix_entries_found:
        return None, None, None
         
    return synonym_map, group_names, similarity_matrix

@st.cache_data
def calculate_total_frequency_per_group(similarity_matrix, group_names):
    """Vypoƒç√≠ta s√∫ƒçet frekvenci√≠ pre V≈†ETKY kanonick√© druhy pre ka≈æd√Ω biotyp (Max Score)."""
    total_frequency = defaultdict(int)
    all_groups = set(group_names.keys())

    for canonical_name in similarity_matrix:
        species_data = similarity_matrix[canonical_name]
        for group_id, count in species_data.items():
            if group_id in all_groups:
                total_frequency[group_id] += count
    
    return dict(total_frequency)


def get_canonical_name(species_name, synonym_map):
    """Z√≠ska kanonick√© meno druhu, ak existuje, inak vr√°ti p√¥vodn√© meno."""
    species_name = species_name.strip()
    return synonym_map.get(species_name, species_name)

@st.cache_data
def get_all_known_species(synonym_map, similarity_matrix):
    """Z√≠ska zjednoten√Ω zoznam v≈°etk√Ωch zn√°mych druhov a synon√Ωm."""
    canonical_species = set(similarity_matrix.keys())
    all_known = canonical_species.union(set(synonym_map.keys())).union(set(synonym_map.values()))
    return sorted(list(all_known))

# --- ANALYTICK√Å FUNKCIA S NOV√ùM FQI V√ùPOƒåTOM ---

@st.cache_data(show_spinner="Prebieha v√Ωpoƒçet Frekvenƒçn√©ho Indexu (FQI)...")
def analyze_similarity(species_list, synonym_map, group_names, similarity_matrix, total_frequency_per_group):
    """
    Vyhodnot√≠ podobnos≈• k biotopom (skupin√°m).
    FQI = (Kumulat√≠vne sk√≥re zadan√Ωch druhov / Celkov√© mo≈æn√© sk√≥re skupiny) * 100
    Tie≈æ sleduje, ktor√© vstupy boli preskoƒçen√© (kanonick√Ω duplik√°t).
    """
    
    cumulative_scores = defaultdict(int)
    valid_groups = set(group_names.keys())
    processed_canonical_species = set() 
    name_conversion_map = {} 
    ignored_inputs = [] 
    
    # 1. KUMULAT√çVNE Sƒå√çTANIE A KONVERZIA
    for user_species in species_list:
        user_species = user_species.strip()
        canonical_name = get_canonical_name(user_species, synonym_map)
        
        if canonical_name in similarity_matrix:
            
            name_conversion_map[user_species] = canonical_name

            if canonical_name not in processed_canonical_species:
                processed_canonical_species.add(canonical_name)
                
                species_data = similarity_matrix[canonical_name]
                for group_id, count in species_data.items():
                    if group_id in valid_groups:
                        cumulative_scores[group_id] += count
            else:
                # Kanonick√Ω druh bol u≈æ spracovan√Ω, tento vstup ignorujeme
                ignored_inputs.append(user_species)
                

    if not cumulative_scores:
        return None, processed_canonical_species, name_conversion_map, ignored_inputs 

    # 2. V√ùPOƒåET FQI (Percentu√°lna normaliz√°cia)
    fqi_scores = {}
    
    for group_id, cumulative_score in cumulative_scores.items():
        max_score = total_frequency_per_group.get(group_id, 0)
        
        if max_score > 0:
            fqi = (cumulative_score / max_score) * 100
            fqi_scores[group_id] = fqi
        else:
            fqi_scores[group_id] = 0.0

    # 3. ZORADENIE A V√ùBER TOP 3
    sorted_scores = sorted(fqi_scores.items(), key=lambda item: item[1], reverse=True)
    top_matches_data = []
    
    # Regex pre robustn√∫ extrakciu k√≥du (prv√Ω non-whitespace token) a zvy≈°ku n√°zvu
    re_biotope_code_extractor = re.compile(r'^(\S+)\s+(.*)', re.IGNORECASE)

    for rank, (group_id, score) in enumerate(sorted_scores[:3]):
        biotope_full_name = group_names.get(group_id, f"Nezn√°my Biotop ({group_id})")
        
        # P√¥vodn√Ω group_id (napr. Group42) ako fallback
        biotope_code = group_id 
        biotope_name = biotope_full_name

        match_code = re_biotope_code_extractor.match(biotope_full_name)
        
        if match_code:
            # Ak regex n√°jde zhodu
            biotope_code = match_code.group(1).strip() 
            biotope_name = match_code.group(2).strip()
            
            # Odstr√°nenie voliteƒænej pomlƒçky/medzier na zaƒçiatku n√°zvu, ak tam zostala
            if biotope_name.startswith('-'):
                 biotope_name = biotope_name[1:].strip()

        
        top_matches_data.append({
            'Poradie': rank + 1,
            'K√ìD Biotopu': biotope_code, # Zobrazi≈• skratku LES05.1a, TRB01a atƒè.
            'N√°zov Biotopu': biotope_name, # Zobrazi≈• pln√Ω n√°zov
            'FQI (% Zhody)': f"{score:.2f} %", 
        })

    return top_matches_data, processed_canonical_species, name_conversion_map, ignored_inputs

# --- AKCIE PRE TLAƒåIDL√Å (Callbacks) ---

def calculate_fqi_action():
    """Ulo≈æ√≠ aktu√°lny v√Ωber a prepne re≈æim na zobrazenie v√Ωsledkov."""
    st.session_state['calculated_species'] = st.session_state.selected_species_multiselect
    st.session_state['app_mode'] = 'results'

def reset_selection_action():
    """Prepne re≈æim sp√§≈• na v√Ωber."""
    st.session_state['app_mode'] = 'selection'


# --- HLAVN√Å WEB APLIK√ÅCIA ---

def biotope_web_app():
    
    st.set_page_config(page_title="Identifik√°tor Biotopov (FQI)", layout="wide")
    
    st.title("üåø Identifik√°tor Biotopov (FQI) na z√°klade Expertn√©ho Syst√©mu")
    st.caption(f"D√°ta naƒç√≠tan√© zo s√∫boru: **{CATALOG_FILENAME}**")

    # NOV√Å SEKCIA: Cit√°cia
    st.markdown("""
        **Podƒæa publik√°cie:**
        ≈†uvada R. (ed.), 2023: Katal√≥g biotopov Slovenska. Druh√©, roz≈°√≠ren√© vydanie. ‚Äì
        ≈†t√°tna ochrana pr√≠rody SR, Bansk√° Bystrica, 511 p. ISBN 978-80-8184-106-4
    """)
    st.markdown("---")


    # Inicializ√°cia stavu
    if 'app_mode' not in st.session_state:
        st.session_state['app_mode'] = 'selection'
        st.session_state['calculated_species'] = [] 

    # Krok 0: Naƒç√≠tanie a parsovanie d√°t (Cache d√°ta)
    catalog_text = load_file_content(CATALOG_FILENAME)
    if catalog_text is None:
        return

    synonym_map, group_names, similarity_matrix = parse_catalog_data(catalog_text)
    if synonym_map is None: 
        st.error("Nepodarilo sa spracova≈• d√°ta z katal√≥gu. Skontrolujte jeho form√°tovanie.")
        return
        
    all_species = get_all_known_species(synonym_map, similarity_matrix)
    total_frequency_per_group = calculate_total_frequency_per_group(similarity_matrix, group_names)

    # Sidebar ≈°tatistiky
    st.sidebar.header("≈†tatistiky D√°t")
    st.sidebar.write(f"Biotopov (skup√≠n): **{len(group_names)}**")
    st.sidebar.write(f"Spracovan√Ωch druhov v matici: **{len(similarity_matrix)}**")
    st.sidebar.write(f"Celkov√Ω poƒçet n√°zvov/synon√Ωm na v√Ωber: **{len(all_species)}**")


    # --- RIADENIE RE≈ΩIMU APLIK√ÅCIE ---

    if st.session_state['app_mode'] == 'selection':
        # Re≈æim 1: V√ùBER DRUHOV

        st.header("1. V√Ωber Druhov")
        st.warning("V√Ωpoƒçet FQI sa spust√≠ a≈æ po stlaƒçen√≠ tlaƒçidla 'V≈°etky druhy zadan√©, vypoƒç√≠taj' pod zoznamom. To zaruƒçuje plynul√Ω v√Ωber.")
        
        current_species_list = st.multiselect(
            "Vyberte druh zo zoznamu (zaƒçnite p√≠sa≈• pre filtrovanie):",
            options=all_species,
            default=st.session_state['calculated_species'], 
            key="selected_species_multiselect" 
        )
        
        st.info(f"Aktu√°lne vybran√Ωch druhov: **{len(current_species_list)}**")
        
        if current_species_list:
            st.button(
                "üü¢ V≈°etky druhy zadan√©, vypoƒç√≠taj", 
                on_click=calculate_fqi_action, 
                use_container_width=True
            )
        else:
            st.button("V≈°etky druhy zadan√©, vypoƒç√≠taj", disabled=True, use_container_width=True)


    elif st.session_state['app_mode'] == 'results':
        # Re≈æim 2: ZOBRAZENIE V√ùSLEDKOV

        user_species_list = st.session_state['calculated_species']

        if not user_species_list:
            st.error("Chyba: Neboli n√°jden√© ≈æiadne druhy na anal√Ωzu. Prepnite sp√§≈• na v√Ωber.")
            st.button("‚¨ÖÔ∏è Zme≈à druhov√∫ skupinu", on_click=reset_selection_action)
            return

        st.header("2. V√Ωsledky Anal√Ωzy FQI")
        
        st.button("‚¨ÖÔ∏è Zme≈à druhov√∫ skupinu", on_click=reset_selection_action)
        
        st.markdown("---")
        
        st.info(f"Anal√Ωza be≈æ√≠ pre **{len(user_species_list)}** vybran√Ωch druhov.")

        # Spustenie FQI anal√Ωzy (cache)
        top_matches_data, processed_species, name_conversion_map, ignored_inputs = analyze_similarity(
            user_species_list, synonym_map, group_names, similarity_matrix, total_frequency_per_group
        )
        
        if top_matches_data is None:
            st.error("Nena≈°iel sa ≈æiaden zadan√Ω druh v matici podobnosti. V√Ωpoƒçet FQI nie je mo≈æn√Ω.")
            return

        # Krok 3: Zobrazenie v√Ωsledkov
        
        # 3.1. TOP 3 ZHODY
        st.subheader("Biotopy s najvy≈°≈°ou podobnos≈•ou (FQI)")
        
        df_results = pd.DataFrame(top_matches_data).set_index('Poradie')
        st.dataframe(df_results, use_container_width=True)

        st.caption("FQI (Frekvenƒçn√Ω Index) je **Percento (v %)**, ktor√© vyjadruje podiel s√∫ƒçtu frekvenci√≠ vybran√Ωch druhov na celkovej mo≈ænej frekvencii v≈°etk√Ωch kanonick√Ωch druhov v danej skupine. Vy≈°≈°ie percento = Vy≈°≈°ia zhoda.")

        st.markdown("---")
        
        # 3.2. Detail konverzi√≠ a spracovan√Ωch druhov
        st.subheader("Detaily Spracovania")

        col1, col2, col3 = st.columns(3) 

        with col1:
            st.markdown("##### Spracovan√© druhy (kanonick√©)")
            st.write(f"**Poƒçet spracovan√Ωch kanonick√Ωch druhov:** {len(processed_species)}")
            
            with st.expander("Zobrazi≈• pou≈æit√© kanonick√© n√°zvy"):
                st.code("\n".join(processed_species))

        with col2:
            conversions = {original: canonical for original, canonical in name_conversion_map.items() if original != canonical}
            
            st.markdown(f"##### Konverzie Synonym (zadan√Ω ‚Üí kanonick√Ω)")
            
            if conversions:
                df_conversions = pd.DataFrame(list(conversions.items()), columns=['Zadan√Ω n√°zov', 'Kanonick√Ω n√°zov'])
                st.dataframe(df_conversions, use_container_width=True, hide_index=True)
            else:
                st.success("Neboli zadan√© ≈æiadne synonym√°.")

        with col3:
            st.markdown(f"##### Ignorovan√© duplik√°ty vstupu")
            
            if ignored_inputs:
                st.warning(f"**Ignorovan√Ωch vstupov: {len(ignored_inputs)}**")
                st.caption("Tieto druhy sa mapuj√∫ na kanonick√Ω n√°zov, ktor√Ω u≈æ bol v r√°mci v√Ωpoƒçtu zahrnut√Ω. Boli preskoƒçen√©, aby sa predi≈°lo duplicitn√©mu zapoƒç√≠taniu.")
                with st.expander("Zobrazi≈• ignorovan√© vstupy"):
                    st.code("\n".join(ignored_inputs))
            else:
                st.success("Neboli zadan√© ≈æiadne duplik√°ty (synonym√° ani kanonick√© n√°zvy) k rovnak√©mu kanonick√©mu druhu.")

    # NOV√Å SEKCIA: Copyright Footer
    st.markdown("---")
    st.markdown("<footer><p style='text-align: right; color: gray; font-size: small;'>¬© R√≥bert ≈†uvada 2025</p></footer>", unsafe_allow_html=True)


if __name__ == "__main__":
    biotope_web_app()